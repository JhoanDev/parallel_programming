um programa pode superar as limitações de recursos, como a capacidade de memória e a latência de acesso aos dados, e obter um speedup maior do que o número de processadores (p) em um sistema paralelo, como no exemplo do uso de memória principal ou cache em sistemas com memória distribuída ou compartilhada. Isso ocorre porque, ao distribuir dados entre múltiplos processadores e aproveitar recursos como cache, o sistema pode acessar dados de forma mais eficiente, reduzindo o tempo de execução de forma mais eficaz do que o esperado apenas com o aumento do número de núcleos.